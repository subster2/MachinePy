{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import KFold\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение базы фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year                                               Name\n",
      "Id                                                            \n",
      "1      2003                                    Dinosaur Planet\n",
      "2      2004                         Isle of Man TT 2004 Review\n",
      "3      1997                                          Character\n",
      "4      1994                       Paula Abdul's Get Up & Dance\n",
      "5      2004                           The Rise and Fall of ECW\n",
      "6      1997                                               Sick\n",
      "7      1992                                              8 Man\n",
      "8      2004                         What the #$*! Do We Know!?\n",
      "9      1991                           Class of Nuke 'Em High 2\n",
      "10     2001                                            Fighter\n",
      "11     1999                     Full Frame: Documentary Shorts\n",
      "12     1947                               My Favorite Brunette\n",
      "13     2003  Lord of the Rings: The Return of the King: Ext...\n",
      "14     1982                                 Nature: Antarctica\n",
      "15     1988                   Neil Diamond: Greatest Hits Live\n",
      "16     1996                                          Screamers\n",
      "17     2005                                          7 Seconds\n",
      "18     1994                                   Immortal Beloved\n",
      "19     2000                              By Dawn's Early Light\n",
      "20     1972                                    Seeta Aur Geeta\n",
      "21     2002                                  Strange Relations\n",
      "22     2000                                       Chump Change\n",
      "23     2001  Clifford: Clifford Saves the Day! / Clifford's...\n",
      "24     1981                                My Bloody Valentine\n",
      "25     1997      Inspector Morse 31: Death Is Now My Neighbour\n",
      "26     2004                                    Never Die Alone\n",
      "27     1962  Sesame Street: Elmo's World: The Street We Liv...\n",
      "28     2002                                    Lilo and Stitch\n",
      "29     2001                                            Boycott\n",
      "30     2003                             Something's Gotta Give\n",
      "...     ...                                                ...\n",
      "17741  2004                          Ginger Snaps 2: Unleashed\n",
      "17742  1995                                Catherine the Great\n",
      "17743  2003                               Better Luck Tomorrow\n",
      "17744  2004                         NASCAR: Tony Stewart Smoke\n",
      "17745  2002      Russell Simmons Presents Def Poetry: Season 1\n",
      "17746  1991  Godzilla & Mothra: Battle for Earth / Vs. King...\n",
      "17747  1991                            Eric Clapton: 24 Nights\n",
      "17748  2005        Dog the Bounty Hunter: The Best of Season 1\n",
      "17749  1985                                             No End\n",
      "17750  2005                     The Hee Haw Collection: Vol. 4\n",
      "17751  1993                               Highlander: Season 2\n",
      "17752  2003                                       Out of Order\n",
      "17753  1997                                       Maslin Beach\n",
      "17754  1999                                       On the Ropes\n",
      "17755  2003                           L/R: Licensed by Royalty\n",
      "17756  1935                                       The 39 Steps\n",
      "17757  2002  Ulysses S. Grant: Warrior / President: America...\n",
      "17758  1979                                           Prophecy\n",
      "17759  1972                                  The Big Bird Cage\n",
      "17760  2004                                      Lightning Bug\n",
      "17761  2003                                             Levity\n",
      "17762  1997                                            Gattaca\n",
      "17763  1978                                          Interiors\n",
      "17764  1998                                Shakespeare in Love\n",
      "17765  1969                                 Godzilla's Revenge\n",
      "17766  2002  Where the Wild Things Are and Other Maurice Se...\n",
      "17767  2004                  Fidel Castro: American Experience\n",
      "17768  2000                                              Epoch\n",
      "17769  2003                                        The Company\n",
      "17770  2003                                       Alien Hunter\n",
      "\n",
      "[17763 rows x 2 columns]\n",
      "Wall time: 260 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "movie_titles = pd.read_csv(r'D:\\Bugaychenko\\Netflix\\movie_titles.csv', \n",
    "                           encoding = 'ISO-8859-1', \n",
    "                           header = None, \n",
    "                           names = ['Id', 'Year', 'Name']).set_index('Id')\n",
    "\n",
    "movie_titles = movie_titles.drop(movie_titles[movie_titles.Year.isnull()].index)\n",
    "movie_titles.Year = movie_titles.Year.astype(int)\n",
    "\n",
    "print(movie_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение юзер даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_raw = pd.read_csv(r'D:\\Bugaychenko\\Netflix\\combined_data_1.txt', header=None, \n",
    "                                                                        names=['User', 'Rating', 'Date'], \n",
    "                                                                        usecols=[0, 1, 2])\n",
    "\n",
    "index_films = df_raw[(df_raw.Date.isnull())& (df_raw.Rating.isnull())].index # промежутки с оценками на фильмы\n",
    "\n",
    "\n",
    "# создание столбца №фильма\n",
    "a = np.empty(len(df_raw), dtype=int)\n",
    "k =1\n",
    "for current, next in zip(index_films, index_films[1:]):\n",
    "    a[current:next] = k\n",
    "    k+=1\n",
    "    a[next:] = k\n",
    "df_raw[\"Movie\"] = a\n",
    "\n",
    "\n",
    "df = df_raw.drop(index_films) #удаляем пустые строки\n",
    "df.Rating = df.Rating.astype(int)\n",
    "df = df[df.Movie.isin(movie_titles.index.unique().values)] # проверка присутствия фильмов\n",
    "\n",
    "y = df.Rating.values # таргет\n",
    "np.save('target', y) \n",
    "\n",
    "del df_raw\n",
    "del index_films\n",
    "del a\n",
    "del y\n",
    "\n",
    "#### убрать при пересоздании спарсы\n",
    "#del df\n",
    "#del movie_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание спарс матрицы\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = df.Movie.unique().shape[0]\n",
    "col2 = df.User.unique().shape[0]\n",
    "sparse_dataset = sc.sparse.lil_matrix((df.shape[0], col1 + col2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "customer = {j:i for i, j in enumerate(df.User.unique())}\n",
    "movie = {j:i for i, j in enumerate(df.Movie.unique())}\n",
    "\n",
    "for i, j in enumerate(df.itertuples()):\n",
    "    sparse_dataset[i, customer[j.User]] = 1\n",
    "    sparse_dataset[i, col1 + movie[j.Movie]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dataset = sc.sparse.csr_matrix(sparse_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sparse_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-96eec5e5fc46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_npz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\Bugaychenko\\Netflix\\sparse_dataset.npz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sparse_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "sc.sparse.save_npz(r'D:\\Bugaychenko\\Netflix\\sparse_dataset.npz', sparse_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка спарс сета\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dataset = sc.sparse.load_npz(r'D:\\Bugaychenko\\Netflix\\sparse_dataset.npz')\n",
    "y = np.load('target.npy').reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decrease(lr,lr_dec,epochs):\n",
    "    lr = lr * np.exp(lr_dec*epochs)\n",
    "    return lr\n",
    "\n",
    "def Nonlinear(X):  \n",
    "    #1/2 (X*V)^2 - X^2*V^2\n",
    "    return 1/2 * np.sum(\n",
    "        np.power(X @ V, 2) - X.power(2) @ np.power(V, 2),axis=1, keepdims=True)\n",
    "        \n",
    "def predict(X):\n",
    "    return w0 + X @ w1 + Nonlinear(X)\n",
    "    \n",
    "def fit(X, Y, epochs=5 , batch_size = 100, lr=0.001, lr_dec=0.001, d=5):\n",
    "    global w0 \n",
    "    global w1 \n",
    "    global V\n",
    "\n",
    "    w0 = 0\n",
    "    w1 = np.ones((X.shape[1], 1))\n",
    "    V = np.ones((X.shape[1], d))\n",
    "    n = X.shape[0]\n",
    "    Z = None\n",
    "    \n",
    "    for epoch in range(0, epochs):\n",
    "        batch_indices = np.random.choice(n, batch_size)\n",
    "        x = X[batch_indices, :]\n",
    "        y = Y[batch_indices]\n",
    "        y_hat = predict(x)\n",
    "        dy = 2 * (y_hat - y) # производная mse\n",
    "        w0 -= np.mean(dy) * lr \n",
    "        w1 -= x.multiply(dy).mean(axis=0).T * lr\n",
    "        Z = x @ V\n",
    "        for i in range(d):\n",
    "            left = x.multiply(Z[:, i].reshape(-1, 1))\n",
    "            right = x.power(2).multiply(V[:, i])\n",
    "            V[:, i] -= (np.asarray((left - right).multiply(dy).mean(axis=0).T) * lr).flatten() \n",
    "        lr = lr_decrease(lr,lr_dec,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold\n",
      "2 fold\n",
      "3 fold\n",
      "4 fold\n",
      "5 fold\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rmse_train = []\n",
    "rmse_test = []\n",
    "kfold = KFold(n_splits=5)\n",
    "count = 0\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(sparse_dataset, y, test_size=0.4, random_state=2)\n",
    "# FM2 = fit(X_train, y_train,epochs=16, batch_size=1000, lr=0.3, lr_dec=0.002, d=2)\n",
    "# print(np.sqrt(sk.metrics.mean_squared_error(y_test, predict(X_test))))\n",
    "# print(np.sqrt(sk.metrics.mean_squared_error(y_train, predict(X_train))))\n",
    "\n",
    "\n",
    "for indexTrain, indexTest in kfold.split(sparse_dataset):\n",
    "    \n",
    "    X_train = sparse_dataset[indexTrain]\n",
    "    y_train = y[indexTrain]\n",
    "    \n",
    "    X_test = sparse_dataset[indexTest]\n",
    "    y_test = y[indexTest]\n",
    "    FM2 = fit(X_train, y_train,epochs=16, batch_size=1000, lr=0.3, lr_dec=0.003, d=5)\n",
    "\n",
    "    rmse_test.append(np.sqrt(sk.metrics.mean_squared_error(y_test, predict(X_test))))\n",
    "    rmse_train.append(np.sqrt(sk.metrics.mean_squared_error(y_train, predict(X_train))))\n",
    "    \n",
    "    count += 1\n",
    "    print('{} fold'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_train</th>\n",
       "      <td>1.074544</td>\n",
       "      <td>1.073932</td>\n",
       "      <td>1.073095</td>\n",
       "      <td>1.070737</td>\n",
       "      <td>1.071435</td>\n",
       "      <td>1.072749</td>\n",
       "      <td>0.001622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test</th>\n",
       "      <td>1.073970</td>\n",
       "      <td>1.078387</td>\n",
       "      <td>1.090617</td>\n",
       "      <td>1.100161</td>\n",
       "      <td>1.094613</td>\n",
       "      <td>1.087550</td>\n",
       "      <td>0.011031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4      mean  \\\n",
       "rmse_train  1.074544  1.073932  1.073095  1.070737  1.071435  1.072749   \n",
       "rmse_test   1.073970  1.078387  1.090617  1.100161  1.094613  1.087550   \n",
       "\n",
       "                 std  \n",
       "rmse_train  0.001622  \n",
       "rmse_test   0.011031  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.vstack([rmse_train, rmse_test]), index=[\n",
    "    'rmse_train',\n",
    "    'rmse_test',\n",
    "])\n",
    "\n",
    "df = pd.concat([df, df.mean(axis=1).rename('mean'), df.std(axis=1).rename('std')], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
