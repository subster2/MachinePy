{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import KFold\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение базы фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year                                               Name\n",
      "Id                                                            \n",
      "1      2003                                    Dinosaur Planet\n",
      "2      2004                         Isle of Man TT 2004 Review\n",
      "3      1997                                          Character\n",
      "4      1994                       Paula Abdul's Get Up & Dance\n",
      "5      2004                           The Rise and Fall of ECW\n",
      "6      1997                                               Sick\n",
      "7      1992                                              8 Man\n",
      "8      2004                         What the #$*! Do We Know!?\n",
      "9      1991                           Class of Nuke 'Em High 2\n",
      "10     2001                                            Fighter\n",
      "11     1999                     Full Frame: Documentary Shorts\n",
      "12     1947                               My Favorite Brunette\n",
      "13     2003  Lord of the Rings: The Return of the King: Ext...\n",
      "14     1982                                 Nature: Antarctica\n",
      "15     1988                   Neil Diamond: Greatest Hits Live\n",
      "16     1996                                          Screamers\n",
      "17     2005                                          7 Seconds\n",
      "18     1994                                   Immortal Beloved\n",
      "19     2000                              By Dawn's Early Light\n",
      "20     1972                                    Seeta Aur Geeta\n",
      "21     2002                                  Strange Relations\n",
      "22     2000                                       Chump Change\n",
      "23     2001  Clifford: Clifford Saves the Day! / Clifford's...\n",
      "24     1981                                My Bloody Valentine\n",
      "25     1997      Inspector Morse 31: Death Is Now My Neighbour\n",
      "26     2004                                    Never Die Alone\n",
      "27     1962  Sesame Street: Elmo's World: The Street We Liv...\n",
      "28     2002                                    Lilo and Stitch\n",
      "29     2001                                            Boycott\n",
      "30     2003                             Something's Gotta Give\n",
      "...     ...                                                ...\n",
      "17741  2004                          Ginger Snaps 2: Unleashed\n",
      "17742  1995                                Catherine the Great\n",
      "17743  2003                               Better Luck Tomorrow\n",
      "17744  2004                         NASCAR: Tony Stewart Smoke\n",
      "17745  2002      Russell Simmons Presents Def Poetry: Season 1\n",
      "17746  1991  Godzilla & Mothra: Battle for Earth / Vs. King...\n",
      "17747  1991                            Eric Clapton: 24 Nights\n",
      "17748  2005        Dog the Bounty Hunter: The Best of Season 1\n",
      "17749  1985                                             No End\n",
      "17750  2005                     The Hee Haw Collection: Vol. 4\n",
      "17751  1993                               Highlander: Season 2\n",
      "17752  2003                                       Out of Order\n",
      "17753  1997                                       Maslin Beach\n",
      "17754  1999                                       On the Ropes\n",
      "17755  2003                           L/R: Licensed by Royalty\n",
      "17756  1935                                       The 39 Steps\n",
      "17757  2002  Ulysses S. Grant: Warrior / President: America...\n",
      "17758  1979                                           Prophecy\n",
      "17759  1972                                  The Big Bird Cage\n",
      "17760  2004                                      Lightning Bug\n",
      "17761  2003                                             Levity\n",
      "17762  1997                                            Gattaca\n",
      "17763  1978                                          Interiors\n",
      "17764  1998                                Shakespeare in Love\n",
      "17765  1969                                 Godzilla's Revenge\n",
      "17766  2002  Where the Wild Things Are and Other Maurice Se...\n",
      "17767  2004                  Fidel Castro: American Experience\n",
      "17768  2000                                              Epoch\n",
      "17769  2003                                        The Company\n",
      "17770  2003                                       Alien Hunter\n",
      "\n",
      "[17763 rows x 2 columns]\n",
      "Wall time: 457 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "movie_titles = pd.read_csv(r'D:\\Bugaychenko\\Netflix\\movie_titles.csv', \n",
    "                           encoding = 'ISO-8859-1', \n",
    "                           header = None, \n",
    "                           names = ['Id', 'Year', 'Name']).set_index('Id')\n",
    "\n",
    "movie_titles = movie_titles.drop(movie_titles[movie_titles.Year.isnull()].index)\n",
    "movie_titles.Year = movie_titles.Year.astype(int)\n",
    "\n",
    "print(movie_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение юзер даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24053764\n",
      "1\n",
      "51031355\n",
      "2\n",
      "73632984\n",
      "3\n",
      "100480507\n",
      "4\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k =1\n",
    "for i in range(1,5):\n",
    "    df_raw = pd.read_csv(r'D:\\Bugaychenko\\Netflix\\combined_data_{}.txt'.format(i), header=None, \n",
    "                                                                            names=['User', 'Rating', 'Date'], \n",
    "                                                                            usecols=[0, 1, 2])\n",
    "    index_films = df_raw[(df_raw.Date.isnull())& (df_raw.Rating.isnull())].index # промежутки с оценками на фильмы\n",
    "    df_raw = df_raw.drop('Date', 1)\n",
    "    #df_raw = df_raw.drop('Rating', 1)\n",
    "    # создание столбца №фильма\n",
    "    a = np.empty(len(df_raw), dtype=int)\n",
    "    for current, next in zip(index_films, index_films[1:]):\n",
    "        a[current:next] = k\n",
    "        k+=1\n",
    "        a[next:] = k\n",
    "    df_raw[\"Movie\"] = a\n",
    "    df = df_raw.drop(index_films) #удаляем пустые строки\n",
    "    df.Rating = df.Rating.astype(int)\n",
    "    #df = df[df.Movie.isin(movie_titles.index.unique().values)] # проверка присутствия фильмов\n",
    "    \n",
    "    if(i == 1):\n",
    "        df_merge = df\n",
    "    else:\n",
    "        df_merge = df_merge.append(df, ignore_index=True)\n",
    "        \n",
    "    print(len(df_merge))\n",
    "    #y.append(df.Rating.values) # таргет\n",
    "    #shpe_df.append(df.shape[0])\n",
    "    #unic_user.append(df.User.unique())\n",
    "    #np.save('target2', y) \n",
    "    \n",
    "    del df_raw\n",
    "    del index_films\n",
    "    del a\n",
    "    del df\n",
    "    print(i)\n",
    "    #del y\n",
    "   \n",
    "    #### убрать при пересоздании спарсы\n",
    "    #del df\n",
    "    #del movie_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sys\n",
    "print(sys.getsizeof(df_merge))\n",
    "#np.save('target_all',df_merge.Rating.values)\n",
    "df_merge = df_merge.drop(df_merge.Rating, axis=1)\n",
    "print(sys.getsizeof(df_merge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание спарс матрицы\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              User  Rating  Movie\n",
      "0          1488844       3      1\n",
      "1           822109       5      1\n",
      "2           885013       4      1\n",
      "3            30878       4      1\n",
      "4           823519       3      1\n",
      "5           893988       3      1\n",
      "6           124105       4      1\n",
      "7          1248029       3      1\n",
      "8          1842128       4      1\n",
      "9          2238063       3      1\n",
      "10         1503895       4      1\n",
      "11         2207774       5      1\n",
      "12         2590061       3      1\n",
      "13            2442       3      1\n",
      "14          543865       4      1\n",
      "15         1209119       4      1\n",
      "16          804919       4      1\n",
      "17         1086807       3      1\n",
      "18         1711859       4      1\n",
      "19          372233       5      1\n",
      "20         1080361       3      1\n",
      "21         1245640       3      1\n",
      "22          558634       4      1\n",
      "23         2165002       4      1\n",
      "24         1181550       3      1\n",
      "25         1227322       4      1\n",
      "26          427928       4      1\n",
      "27          814701       5      1\n",
      "28          808731       4      1\n",
      "29          662870       5      1\n",
      "...            ...     ...    ...\n",
      "100480477  1882093       3  17767\n",
      "100480478   789449       2  17767\n",
      "100480479   737905       3  17767\n",
      "100480480   834423       3  17767\n",
      "100480481   892826       2  17767\n",
      "100480482  2142868       4  17767\n",
      "100480483   953604       3  17767\n",
      "100480484  2331946       1  17767\n",
      "100480485  1205647       3  17767\n",
      "100480486   357707       3  17767\n",
      "100480487  1933317       3  17767\n",
      "100480488   982006       3  17767\n",
      "100480489   111084       2  17767\n",
      "100480490   635735       4  17767\n",
      "100480491  2167041       4  17767\n",
      "100480492   925414       4  17767\n",
      "100480493  1983962       2  17767\n",
      "100480494   897629       3  17767\n",
      "100480495  1274035       4  17767\n",
      "100480496  2641559       3  17767\n",
      "100480497   834323       2  17767\n",
      "100480498   516110       5  17767\n",
      "100480499   365996       3  17767\n",
      "100480500   986348       4  17767\n",
      "100480501   311124       3  17767\n",
      "100480502  1790158       4  17767\n",
      "100480503  1608708       3  17767\n",
      "100480504   234275       1  17767\n",
      "100480505   255278       4  17767\n",
      "100480506   453585       2  17767\n",
      "\n",
      "[100480507 rows x 3 columns]\n",
      "17767\n",
      "480189\n",
      "24053764\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(df_merge)\n",
    "col1 = df_merge.Movie.unique().shape[0]\n",
    "#col1 = 17767\n",
    "print(col1)\n",
    "col2 = df_merge.User.unique().shape[0]\n",
    "#col2 = 480189\n",
    "print(col2)\n",
    "X = df_merge[:24053764].shape[0]\n",
    "print(X)\n",
    "#del df_merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_merge[73632984:].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sparse_dataset = sc.sparse.lil_matrix((X, col1 + col2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "customer = {j:i for i, j in enumerate(df_merge.User.unique())}\n",
    "movie = {j:i for i, j in enumerate(df_merge.Movie.unique())}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, j in enumerate(df_merge[73632984:].itertuples()):\n",
    "    sparse_dataset[i, customer[j.User]] = 1\n",
    "    sparse_dataset[i, col1 + movie[j.Movie]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sparse_dataset = sc.sparse.csr_matrix(sparse_dataset)\n",
    "sc.sparse.save_npz(r'D:\\Bugaychenko\\Netflix\\sparse_dataset_super4.npz', sparse_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка спарс сета\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dataset1 = sc.sparse.load_npz(r'D:\\Bugaychenko\\Netflix\\sparse_dataset_super1.npz')\n",
    "sparse_dataset2 = sc.sparse.load_npz(r'D:\\Bugaychenko\\Netflix\\sparse_dataset_super2.npz')\n",
    "sparse_dataset3 = sc.sparse.load_npz(r'D:\\Bugaychenko\\Netflix\\sparse_dataset_super3.npz')\n",
    "sparse_dataset4 = sc.sparse.load_npz(r'D:\\Bugaychenko\\Netflix\\sparse_dataset_super4.npz')\n",
    "\n",
    "sparse_dataset = sc.sparse.vstack((sparse_dataset1, sparse_dataset2, sparse_dataset3, sparse_dataset4))\n",
    "\n",
    "y = np.load('target_all.npy').reshape(-1, 1)\n",
    "\n",
    "del sparse_dataset1\n",
    "del sparse_dataset2\n",
    "del sparse_dataset3\n",
    "del sparse_dataset4\n",
    "\n",
    "\n",
    "#sparse_dataset = joblib.load('sparse_df_2.bin')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100480507x497956 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 200960424 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100480507"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_score(y_pred, y_real):\n",
    "    return np.sqrt(np.sum(np.power(y_pred - y_real, 2)) / y_pred.shape[0])\n",
    "\n",
    "def lr_decrease(lr,lr_dec,epochs):\n",
    "    lr = lr * np.exp(-lr_dec*epochs)\n",
    "    return lr\n",
    "\n",
    "def Nonlinear(X):\n",
    "    global Z\n",
    "    global X_squared\n",
    "    X_squared = X.power(2)\n",
    "    Z = X @ V\n",
    "    #1/2 (X*V)^2 - X^2*V^2\n",
    "    return 1/2 * np.sum(\n",
    "        np.power(Z, 2) - X_squared @ np.power(V, 2),axis=1, keepdims=True)\n",
    "        \n",
    "def predict(X):\n",
    "    return w0 + X @ w1 + Nonlinear(X)\n",
    "    \n",
    "def fit(X, Y, mini_batches=5 , batch_size = 100, lr=0.001, lr_dec=0.001, k=5):\n",
    "    global w0 \n",
    "    global w1 \n",
    "    global V\n",
    "    \n",
    "    \n",
    "    w0 = 0\n",
    "    w1 = np.random.normal(size=(X.shape[1], 1), scale=.1)\n",
    "    V = np.random.normal(size=(X.shape[1], k), scale=.1)\n",
    "    n = X.shape[0]\n",
    "    lr_new = lr\n",
    "    \n",
    "    for epoch in range(0, mini_batches):\n",
    "        batch_indices = np.random.choice(n, batch_size)\n",
    "        x = X[batch_indices, :]\n",
    "        y = Y[batch_indices]\n",
    "        y_hat = predict(x)\n",
    "        dy = 2 * (y_hat - y) \n",
    "        w0 -= np.mean(dy) * lr_new \n",
    "        w1 -= x.multiply(dy).mean(axis=0).T * lr_new\n",
    "        for i in range(k):\n",
    "            left = x.multiply(Z[:, i].reshape(-1, 1)) #X*XV\n",
    "            right = X_squared.multiply(V[:, i]) #X^2*V\n",
    "            V[:, i] -= (np.asarray((left - right).multiply(dy).mean(axis=0).T) * lr_new).flatten() \n",
    "        lr_new = lr_decrease(lr,lr_dec,epoch)\n",
    "        if(epoch %10000 == 0):\n",
    "            print(epoch)\n",
    "            print(lr_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.3\n",
      "10000\n",
      "0.27145122541078787\n",
      "20000\n",
      "0.24561922592339452\n",
      "30000\n",
      "0.22224546620451535\n",
      "40000\n",
      "0.20109601381069178\n",
      "50000\n",
      "0.18195919791379003\n",
      "60000\n",
      "0.16464349082820792\n",
      "70000\n",
      "0.14897559113742284\n",
      "80000\n",
      "0.13479868923516647\n",
      "90000\n",
      "0.12197089792217973\n",
      "100000\n",
      "0.1103638323514327\n",
      "Wall time: 1h 46min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FM2 = fit(sparse_dataset, y, mini_batches=sparse_dataset.shape[0]//1000, batch_size=1000, lr=0.3, lr_dec=0.00001, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9839960865827178"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk.metrics.mean_squared_error(y[:50000000], predict(sparse_dataset[:50000000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9811352453519191"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk.metrics.mean_squared_error(y[50000000:], predict(sparse_dataset[50000000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912445036252753"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt((0.9839960865827178+0.9811352453519191)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dataset1 = sc.sparse.load_npz(r'D:\\Bugaychenko\\Netflix\\sparse_dataset_super1.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9937534158189794"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(sk.metrics.mean_squared_error(y[:sparse_dataset1.shape[0]], predict(sparse_dataset1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
